# ğŸ” VerifyVision-Pro ğŸ–¼ï¸

<div align="center">
  
![Status](https://img.shields.io/badge/status-active-success.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.7+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)

**æ·±åº¦å­¦ä¹ é©±åŠ¨çš„å›¾åƒä¼ªé€ æ£€æµ‹ç³»ç»Ÿ**  
**A Deep Learning-Powered Image Forgery Detection System**

[English](#english-documentation) | [ä¸­æ–‡](#chinese-documentation)

</div>

---

<a name="english-documentation"></a>
# English Documentation ğŸŒ

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [System Requirements](#system-requirements)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Data Preparation](#data-preparation)
- [Model Training](#model-training)
- [Model Evaluation](#model-evaluation)
- [Web Application](#web-application)
- [Technical Implementation](#technical-implementation)
- [Advanced Usage](#advanced-usage)
- [Performance Optimization](#performance-optimization)
- [Troubleshooting](#troubleshooting)
- [Notes & Best Practices](#notes)
- [Contributing](#contributing)
- [License](#license)

## ğŸ”­ Overview <a name="overview"></a>

VerifyVision-Pro is a comprehensive deep learning-based system designed to detect image forgeries with high accuracy. The system integrates robust data processing pipelines, state-of-the-art deep learning models, and an intuitive web interface for real-time detection.

### ğŸŒŸ Key Features

- **Multi-model Support**: Implements various architectures (EfficientNet, ResNet, Xception, CNN)
- **Comprehensive Pipeline**: Complete workflow from data preparation to deployment
- **User-friendly Interface**: Web-based UI for easy interaction with the system
- **Detailed Analytics**: Provides confidence scores and visualization of results
- **Optimized Performance**: Supports both CPU and GPU inference

## ğŸ“ Project Structure <a name="project-structure"></a>

```
VerifyVision-Pro/
â”‚
â”œâ”€â”€ data/                      # Data directory
â”‚   â”œâ”€â”€ real/                  # Real images
â”‚   â”œâ”€â”€ fake/                  # Forged images
â”‚   â””â”€â”€ processed/             # Preprocessed images
â”‚
â”œâ”€â”€ models/                    # Model directory (gitignored)
â”‚   â””â”€â”€ saved/                 # Saved model weights
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ data_utils/            # Data processing utilities
â”‚   â”‚   â”œâ”€â”€ dataset.py         # Dataset class
â”‚   â”‚   â””â”€â”€ data_processor.py  # Data preprocessing tools
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Model definitions
â”‚   â”‚   â””â”€â”€ models.py          # Deep learning model implementations
â”‚   â”‚
â”‚   â”œâ”€â”€ training/              # Training related
â”‚   â”‚   â”œâ”€â”€ train.py           # Training scripts
â”‚   â”‚   â””â”€â”€ evaluate.py        # Evaluation scripts
â”‚   â”‚
â”‚   â””â”€â”€ web/                   # Web application
â”‚       â””â”€â”€ app.py             # Flask application
â”‚
â”œâ”€â”€ static/                    # Static resources
â”‚   â”œâ”€â”€ css/                   # CSS styles
â”‚   â”‚   â””â”€â”€ style.css          # Custom styles
â”‚   â”‚
â”‚   â”œâ”€â”€ js/                    # JavaScript
â”‚   â”‚   â””â”€â”€ main.js            # Main JS file
â”‚   â”‚
â”‚   â””â”€â”€ uploads/               # User uploaded images
â”‚
â”œâ”€â”€ templates/                 # HTML templates
â”‚   â”œâ”€â”€ base.html              # Base template
â”‚   â”œâ”€â”€ index.html             # Home page
â”‚   â”œâ”€â”€ result.html            # Results page
â”‚   â””â”€â”€ about.html             # About page
â”‚
â”œâ”€â”€ generate_test_images.py    # Test image generation script
â”œâ”€â”€ main.py                    # Project main entry program
â”œâ”€â”€ requirements.txt           # Project dependencies
â””â”€â”€ README.md                  # Project description
```

## ğŸ’» System Requirements <a name="system-requirements"></a>

### Minimum Requirements

- **Python**: 3.7+
- **PyTorch**: 2.0+
- **RAM**: 4GB (CPU only), 8GB (with GPU)
- **Storage**: 1GB for code and basic datasets
- **OS**: Windows 10+, macOS 10.15+, Ubuntu 18.04+

### Recommended Requirements

- **Python**: 3.9+
- **PyTorch**: 2.0+ with CUDA
- **GPU**: NVIDIA GPU with CUDA support (8GB+ VRAM)
- **RAM**: 16GB
- **Storage**: 10GB+ for extended datasets
- **OS**: Ubuntu 20.04+ or macOS 12+

## ğŸ“¦ Installation <a name="installation"></a>

### Step 1: Clone the Repository

```bash
git clone https://github.com/lintsinghua/VerifyVision-Pro.git
cd VerifyVision-Pro
```

### Step 2: Create a Virtual Environment (Recommended)

```bash
# For macOS/Linux
python -m venv imgvenv
source imgvenv/bin/activate

# For Windows
python -m venv imgvenv
imgvenv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Verify Installation

```bash
# Check if PyTorch is properly installed with CUDA (if available)
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
```

### Optional: GPU Setup

If you have an NVIDIA GPU, ensure you have installed the appropriate CUDA toolkit and cuDNN versions compatible with your PyTorch installation.

## ğŸš€ Quick Start <a name="quick-start"></a>

Follow this guide to quickly set up and run the VerifyVision-Pro system:

### Step 1: Generate Test Data ğŸ²

First, generate sample images for testing the system:

```bash
python generate_test_images.py
```

This creates 20 real images and 20 fake images in the respective data directories.

### Step 2: Preprocess Images ğŸ–Œï¸

Prepare the images for model training:

```bash
# Process real images
python main.py preprocess --input-dir data/real --output-dir data/processed/real --target-size 224 224

# Process fake images
python main.py preprocess --input-dir data/fake --output-dir data/processed/fake --target-size 224 224
```

### Step 3: Train a Model ğŸ§ 

Train a basic CNN model using the preprocessed data:

```bash
python main.py train \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model cnn \
  --pretrained \
  --epochs 5 \
  --batch-size 4 \
  --save-dir models/saved
```

> **Note**: For initial testing, a small number of epochs (5) is sufficient. Increase for better performance.

### Step 4: Launch Web Application ğŸŒ

Start the web interface to interact with your trained model:

```bash
python main.py web \
  --model-path models/saved/best_model.pth \
  --model-name cnn \
  --port 8080 \
  --debug
```

> **Important**: On macOS, port 5000 may be occupied by AirPlay service. Using port 8080 is recommended.

### Step 5: Access the Application ğŸ–±ï¸

Open your browser and visit [http://localhost:8080](http://localhost:8080) to use the system.

## ğŸ“Š Data Preparation <a name="data-preparation"></a>

### Obtaining Datasets ğŸ“¥

Several methods are available to gather data for training and testing:

#### Method 1: Test Data Generation (Recommended for Beginners)

The built-in script generates synthetic data for testing purposes:

```bash
python generate_test_images.py
```

**What it does:**
- Creates `data/real` and `data/fake` directories
- Generates 20 sample real images with random content
- Creates 20 corresponding fake images with manipulations
- Suitable for initial system testing and validation

#### Method 2: Public Datasets

Access information about public image forgery detection datasets:

```bash
python main.py download-info
```

This displays links to valuable datasets commonly used in image forgery detection research, including:
- CASIA v1.0 and v2.0
- Columbia Image Splicing Detection
- CoMoFoD (Copy-Move Forgery Dataset)
- Coverage
- IEEE IFS-TC Image Forensics Challenge Dataset

#### Method 3: Custom Dataset Creation

Build your own dataset by:

1. **Collecting real images**:
   - Place authentic images in `data/real` directory
   - Use personal photos or public domain images
   - Ensure diversity in content, lighting, and source devices

2. **Creating fake images**:
   ```bash
   python main.py create-fake \
     --real-dir data/real \
     --fake-dir data/fake \
     --method splice \
     --num-images 1000
   ```

**Available forgery methods:**
- `splice`: Combines regions from different images
- `copy`: Duplicates regions within the same image
- `noise`: Adds localized noise to create inconsistencies
- `color`: Manipulates color properties in specific regions

### Preprocessing Data ğŸ”„

Before training, images need to be preprocessed for consistency:

```bash
python main.py preprocess \
  --input-dir data/real \
  --output-dir data/processed/real \
  --target-size 224 224 \
  --max-images 5000
```

**Preprocessing operations include:**
- Resizing to uniform dimensions
- Normalization
- Optional augmentation (rotation, flipping, etc.)
- Format standardization
- Optional color space conversion

**Parameters:**
- `--input-dir`: Source directory containing images
- `--output-dir`: Destination for processed images
- `--target-size`: Output dimensions (width height)
- `--max-images`: Limit number of images to process (optional)
- `--augment`: Apply data augmentation (optional)

## ğŸ‹ï¸â€â™‚ï¸ Model Training <a name="model-training"></a>

### Training a Model from Scratch

VerifyVision-Pro supports training various deep learning models for image forgery detection:

```bash
python main.py train \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model efficientnet_b0 \
  --pretrained \
  --epochs 30 \
  --batch-size 32 \
  --learning-rate 0.001 \
  --save-dir models/saved \
  --early-stopping \
  --patience 5
```

### Available Models

The system implements several state-of-the-art architectures:

| Model | Description | Parameters | Suitable For |
|-------|-------------|------------|--------------|
| `cnn` | Custom CNN | ~500K | Quick testing, limited data |
| `resnet18` | ResNet-18 | ~11M | Small to medium datasets |
| `resnet50` | ResNet-50 | ~25M | Medium datasets |
| `efficientnet_b0` | EfficientNet-B0 | ~5M | Balanced performance |
| `xception` | Xception | ~22M | Advanced features |

### Training Parameters

The training module offers comprehensive customization:

| Parameter | Description | Default | Notes |
|-----------|-------------|---------|-------|
| `--real-dir` | Real image directory | - | Required |
| `--fake-dir` | Fake image directory | - | Required |
| `--model` | Model architecture | `efficientnet_b0` | See available models |
| `--pretrained` | Use pretrained weights | `False` | Flag |
| `--epochs` | Training epochs | `30` | |
| `--batch-size` | Batch size | `32` | Reduce for less memory |
| `--learning-rate` | Learning rate | `0.001` | |
| `--weight-decay` | L2 regularization | `0.0001` | |
| `--save-dir` | Save directory | `models/saved` | |
| `--early-stopping` | Enable early stopping | `False` | Flag |
| `--patience` | Epochs for early stopping | `5` | |
| `--validation-split` | Validation data ratio | `0.2` | |

### Training Process

During training, the system:

1. Splits data into training and validation sets
2. Loads or initializes the selected model architecture
3. Applies transfer learning if pretrained weights are requested
4. Optimizes using Adam optimizer with specified learning rate
5. Implements learning rate scheduling for better convergence
6. Monitors validation metrics to prevent overfitting
7. Saves the best-performing model based on validation accuracy
8. Generates training curves and performance statistics

### Advanced Training Features

- **Early Stopping**: Automatically stops training when performance plateaus
- **Learning Rate Scheduling**: Reduces learning rate when progress stalls
- **Checkpointing**: Saves model at regular intervals during training
- **Mixed Precision**: Uses FP16 training when supported by hardware
- **Gradient Clipping**: Prevents exploding gradients
- **Data Augmentation**: Optional real-time augmentation during training

## ğŸ“ Model Evaluation <a name="model-evaluation"></a>

### Evaluating Model Performance

After training, assess your model's performance using:

```bash
python main.py evaluate \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model efficientnet_b0 \
  --checkpoint models/saved/best_model.pth \
  --results-dir results \
  --confusion-matrix \
  --roc-curve
```

### Evaluation Metrics

The evaluation module provides comprehensive performance metrics:

| Metric | Description | Range |
|--------|-------------|-------|
| Accuracy | Overall correct predictions | 0-1 |
| Precision | True positives / predicted positives | 0-1 |
| Recall | True positives / actual positives | 0-1 |
| F1 Score | Harmonic mean of precision & recall | 0-1 |
| AUC-ROC | Area Under ROC Curve | 0-1 |
| Confusion Matrix | Visualization of predictions vs. ground truth | - |

### Advanced Evaluation Features

- **Per-class Analysis**: Detailed metrics for real and fake classes
- **Confidence Distribution**: Histogram of prediction confidences
- **Failure Analysis**: Examination of misclassified samples
- **Feature Visualization**: Activation maps showing influential regions
- **Cross-validation**: Optional k-fold cross-validation for robust evaluation

### Interpreting Results

The evaluation results help understand:

- How well the model generalizes to unseen data
- Whether it's biased toward a particular class
- Types of images that cause detection failures
- Confidence level in predictions
- Areas for potential improvement

## ğŸŒ Web Application <a name="web-application"></a>

### Launching the Web Interface

Start the web application to interact with your trained model:

```bash
python main.py web \
  --model-path models/saved/best_model.pth \
  --model-name efficientnet_b0 \
  --port 8080 \
  --host 0.0.0.0 \
  --debug
```

### Web Application Features

The VerifyVision-Pro web interface provides:

- **User-friendly Upload**: Simple drag-and-drop or file selection interface
- **Real-time Analysis**: Immediate processing and results display
- **Visual Feedback**: Clear indication of authenticity with confidence scores
- **Heatmap Visualization**: Optional visualization of suspicious regions
- **Result History**: Session-based history of analyzed images
- **Responsive Design**: Works on desktop and mobile devices

### Setup Parameters

| Parameter | Description | Default | Notes |
|-----------|-------------|---------|-------|
| `--model-path` | Path to model file | - | Required |
| `--model-name` | Model architecture | - | Required |
| `--port` | Server port | `5000` | Use `8080` on macOS |
| `--host` | Host address | `127.0.0.1` | Use `0.0.0.0` for external access |
| `--debug` | Enable debug mode | `False` | Flag |
| `--max-size` | Max upload size (MB) | `5` | |
| `--threshold` | Detection threshold | `0.5` | Range: 0-1 |

### Using the Web Application ğŸ’»

1. **Upload an Image**:
   - Click "Choose File" or drag-and-drop an image onto the upload area
   - Supported formats: JPG, JPEG, PNG
   - Maximum file size: 5MB (configurable)

2. **Analyze the Image**:
   - Click "Upload & Detect" button
   - The system processes the image through the model

3. **View Results**:
   - Real/Fake classification is displayed
   - Confidence score indicates detection certainty
   - Optional heatmap visualization highlights suspicious regions
   - Additional metadata shows image properties

4. **Interpret Results**:
   - Higher confidence scores indicate greater certainty
   - Scores near 0.5 indicate uncertainty
   - Consider using multiple models for ambiguous cases

### Deployment Options

For production deployment, consider:

- **Nginx/Apache**: Set up reverse proxy for better security and performance
- **Docker**: Containerized deployment for consistent environment
- **Cloud Platforms**: AWS, Google Cloud, or Azure for scalability
- **SSL Certificate**: Enable HTTPS for secure communication
- **Rate Limiting**: Prevent abuse of the service

## ğŸ”§ Technical Implementation <a name="technical-implementation"></a>

### Core Technologies

VerifyVision-Pro is built on modern technologies for reliable performance:

#### Data Processing
- **OpenCV**: Image loading, preprocessing, and manipulation
- **PIL (Pillow)**: Image format handling and transformations
- **Albumentations**: Advanced data augmentation pipeline
- **NumPy**: Efficient numerical operations on image data

#### Deep Learning Framework
- **PyTorch**: Primary deep learning framework
- **TorchVision**: Pre-trained models and dataset utilities
- **CUDA**: GPU acceleration for training and inference
- **torchinfo**: Model architecture visualization and analysis

#### Model Architectures
- **EfficientNet**: Resource-efficient convolutional architecture
- **ResNet**: Deep residual networks with skip connections
- **Xception**: Depthwise separable convolutions for efficiency
- **Custom CNN**: Lightweight architecture for basic detection

#### Web Framework
- **Flask**: Lightweight web server implementation
- **Werkzeug**: WSGI utility library for web applications
- **Jinja2**: Templating engine for HTML generation
- **Flask-WTF**: Form handling and validation

#### Frontend
- **Bootstrap**: Responsive design framework
- **JavaScript**: Dynamic client-side functionality
- **Chart.js**: Interactive visualization of results
- **Dropzone.js**: Enhanced file upload experience

### Implementation Details

#### Model Architecture Design

The system implements a two-class classification approach with:

- **Feature Extraction**: Convolutional layers capture spatial features
- **Feature Aggregation**: Pooling operations aggregate local information
- **Classification Head**: Fully connected layers for final prediction
- **Transfer Learning**: Adaptation of pre-trained networks
- **Domain-specific Features**: Custom layers for forgery detection

#### Training Pipeline

The training system implements:

- **Dataset Management**: Custom PyTorch datasets for efficient loading
- **Balanced Sampling**: Ensures equal representation of classes
- **Augmentation Strategy**: Applied during training for robustness
- **Mixed Precision**: FP16 for faster training where supported
- **Distributed Training**: Optional multi-GPU support

#### Inference Pipeline

The inference system includes:

- **Preprocessing**: Consistent with training pipeline
- **Batched Processing**: Efficient handling of multiple images
- **Model Ensemble**: Optional combination of multiple models
- **Post-processing**: Confidence calibration and thresholding
- **Visualization**: Generation of heatmaps for interpretability

## ğŸ”¬ Advanced Usage <a name="advanced-usage"></a>

### Custom Model Development

Extend VerifyVision-Pro with custom model architectures:

1. **Adding a New Model**:
   
   Modify `src/models/models.py` to include your architecture:

   ```python
   class CustomModel(nn.Module):
       def __init__(self, num_classes=2, pretrained=False):
           super(CustomModel, self).__init__()
           # Define your model architecture here
           
       def forward(self, x):
           # Define forward pass
           return x
   ```

2. **Registering the Model**:
   
   Add your model to the model factory:

   ```python
   def get_model(name, num_classes=2, pretrained=False):
       models = {
           # Existing models
           'custom_model': CustomModel,
       }
       return models[name](num_classes=num_classes, pretrained=pretrained)
   ```

3. **Using Your Model**:
   
   ```bash
   python main.py train \
     --real-dir data/processed/real \
     --fake-dir data/processed/fake \
     --model custom_model \
     --epochs 30
   ```

### Advanced Dataset Techniques

Enhance model performance with advanced dataset handling:

#### Synthetic Data Generation

Create additional training data using generative methods:

```bash
python main.py generate-synthetic \
  --base-images data/real \
  --output-dir data/synthetic \
  --count 1000 \
  --techniques "copy,splice,removal,noise"
```

#### Cross-dataset Validation

Test model generalization across different datasets:

```bash
python main.py cross-validate \
  --train-real data/datasetA/real \
  --train-fake data/datasetA/fake \
  --test-real data/datasetB/real \
  --test-fake data/datasetB/fake \
  --model efficientnet_b0
```

#### Active Learning

Implement active learning to prioritize labeling efforts:

```bash
python main.py active-learning \
  --unlabeled data/unlabeled \
  --labeled data/labeled \
  --model-path models/saved/model.pth \
  --selection-method "entropy" \
  --batch-size 100
```

### Model Interpretation

Understand model decisions with advanced visualization:

```bash
python main.py interpret \
  --image path/to/image.jpg \
  --model-path models/saved/model.pth \
  --method "gradcam" \
  --output-dir visualizations
```

Available interpretation methods:
- `gradcam`: Gradient-weighted Class Activation Mapping
- `lime`: Local Interpretable Model-agnostic Explanations
- `shap`: SHapley Additive exPlanations
- `occlusion`: Occlusion sensitivity analysis

## âš¡ Performance Optimization <a name="performance-optimization"></a>

### Hardware Acceleration

Maximize system performance with hardware optimizations:

#### GPU Acceleration

Enable GPU acceleration for faster training and inference:

```bash
# Check GPU availability
python -c "import torch; print(torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU')"

# Train with GPU (automatic if available)
python main.py train --model efficientnet_b0 --batch-size 64 --real-dir data/processed/real --fake-dir data/processed/fake
```

#### Multi-GPU Training

Distribute training across multiple GPUs for larger models:

```bash
python -m torch.distributed.launch --nproc_per_node=4 main.py train \
  --distributed \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model efficientnet_b0 \
  --batch-size 128
```

#### CPU Optimization

Optimize CPU performance when GPU is unavailable:

```bash
# Set number of CPU threads
python main.py train --num-workers 8 --pin-memory --real-dir data/processed/real --fake-dir data/processed/fake
```

### Memory Optimization

Manage memory usage for efficient processing:

#### Batch Size Adjustment

Adjust batch size based on available memory:

| Hardware | Recommended Batch Size |
|----------|------------------------|
| CPU | 8-16 |
| GPU 4GB VRAM | 16-32 |
| GPU 8GB VRAM | 32-64 |
| GPU 16GB+ VRAM | 64-128 |

```bash
# Smaller batch size for limited memory
python main.py train --batch-size 8 --real-dir data/processed/real --fake-dir data/processed/fake

# Larger batch size for high-end systems
python main.py train --batch-size 128 --real-dir data/processed/real --fake-dir data/processed/fake
```

#### Gradient Accumulation

Train with large effective batch sizes on limited memory:

```bash
python main.py train \
  --batch-size 16 \
  --gradient-accumulation 4 \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake
```

This simulates a batch size of 64 (16 Ã— 4) while only requiring memory for 16 samples.

### Inference Optimization

Speed up production deployment:

#### Model Quantization

Reduce model size and increase inference speed:

```bash
python main.py quantize \
  --model-path models/saved/best_model.pth \
  --quantized-model-path models/saved/quantized_model.pth \
  --calibration-images data/processed/real
```

This reduces model size by up to 75% and increases inference speed by 2-4x.

#### Batch Inference

Process multiple images simultaneously:

```bash
python main.py batch-inference \
  --input-dir data/test \
  --output-file results.csv \
  --model-path models/saved/best_model.pth \
  --batch-size 32
```

#### Model Pruning

Remove unnecessary connections for faster inference:

```bash
python main.py prune \
  --model-path models/saved/best_model.pth \
  --pruned-model-path models/saved/pruned_model.pth \
  --prune-ratio 0.3
```

## ğŸ”¨ Troubleshooting <a name="troubleshooting"></a>

### Common Issues and Solutions

This section addresses frequently encountered problems:

### ğŸ”„ Installation Issues

#### CUDA Compatibility Problems

**Symptoms**: PyTorch installation succeeds but CUDA is not detected or crashes occur during GPU operations.

**Solution**:
1. Ensure compatible versions:
   ```bash
   # Check CUDA version
   nvcc --version
   
   # Install compatible PyTorch version
   pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html
   ```

2. Verify installation:
   ```bash
   python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
   ```

#### Package Dependency Conflicts

**Symptoms**: `pip install` fails with dependency conflicts.

**Solution**:
1. Create a fresh virtual environment:
   ```bash
   python -m venv fresh_env
   source fresh_env/bin/activate
   ```

2. Install dependencies one by one:
   ```bash
   pip install numpy
   pip install torch torchvision
   pip install -r requirements.txt
   ```

### ğŸ–¥ï¸ Runtime Issues

#### Port Occupation on macOS

**Symptoms**: Web application fails to start with "Address already in use" error.

**Solution**:
1. Use a different port:
   ```bash
   python main.py web --model-path models/saved/best_model.pth --model-name cnn --port 8080
   ```

2. Or find and kill the process using port 5000:
   ```bash
   sudo lsof -i :5000
   kill -9 <PID>
   ```

#### Out of Memory (OOM) Errors

**Symptoms**: Training crashes with "CUDA out of memory" or system memory errors.

**Solution**:
1. Reduce batch size:
   ```bash
   python main.py train --batch-size 4 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. Use gradient accumulation:
   ```bash
   python main.py train --batch-size 2 --gradient-accumulation 8 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. Use a smaller model:
   ```bash
   python main.py train --model resnet18 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

#### Empty Dataset Errors

**Symptoms**: Training fails with "dataset is empty" errors.

**Solution**:
1. Verify directory paths:
   ```bash
   ls -la data/processed/real data/processed/fake
   ```

2. Check file formats (should be .jpg, .jpeg, or .png):
   ```bash
   find data/processed/real -type f | grep -v -E '\.(jpg|jpeg|png)$'
   ```

3. Generate test data to verify system:
   ```bash
   python generate_test_images.py
   ```

### ğŸ‹ï¸â€â™‚ï¸ Training Issues

#### Poor Model Performance

**Symptoms**: Model achieves low accuracy or doesn't improve during training.

**Solution**:
1. Increase training duration:
   ```bash
   python main.py train --epochs 50 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. Try different models:
   ```bash
   python main.py train --model efficientnet_b0 --pretrained --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. Ensure balanced dataset:
   ```bash
   python main.py analyze-dataset --real-dir data/processed/real --fake-dir data/processed/fake
   ```

4. Enable data augmentation:
   ```bash
   python main.py train --augmentation --real-dir data/processed/real --fake-dir data/processed/fake
   ```

#### Training Plateaus

**Symptoms**: Validation accuracy stops improving early in training.

**Solution**:
1. Adjust learning rate:
   ```bash
   python main.py train --learning-rate 0.0001 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. Implement learning rate scheduling:
   ```bash
   python main.py train --scheduler cosine --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. Try different optimizers:
   ```bash
   python main.py train --optimizer adamw --real-dir data/processed/real --fake-dir data/processed/fake
   ```

#### Overfitting

**Symptoms**: Training accuracy is high but validation accuracy is low.

**Solution**:
1. Add regularization:
   ```bash
   python main.py train --weight-decay 0.001 --dropout 0.3 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. Use early stopping:
   ```bash
   python main.py train --early-stopping --patience 5 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. Increase dataset size or diversity.

## ğŸ“ Notes & Best Practices <a name="notes"></a>

### Practical Recommendations

#### Dataset Quality

The quality of training data directly impacts model performance:

- **Size**: 1,000+ images per class minimum for good performance
- **Balance**: Maintain equal numbers of real and fake images
- **Diversity**: Include various image sources, lighting conditions, and content
- **Authenticity**: Ensure "real" images are truly unmanipulated
- **Realism**: Create forgeries that represent realistic manipulation methods
- **Metadata**: Preserve relevant metadata (camera model, editing software, etc.)

#### Model Selection

Choose models based on your specific requirements:

| Priority | Recommended Model |
|----------|-------------------|
| Speed | `cnn` or `resnet18` |
| Accuracy | `efficientnet_b0` or `xception` |
| Balance | `resnet18` or `efficientnet_b0` |
| Limited Data | `cnn` with heavy augmentation |
| Production | Ensemble of multiple models |

#### Deployment Considerations

For real-world deployment:

- **Security**: Implement rate limiting and file validation
- **Scalability**: Use load balancing for high-traffic applications
- **Privacy**: Consider local processing for sensitive materials
- **Transparency**: Communicate confidence levels and limitations
- **Updates**: Regularly retrain with new forgery techniques
- **Fallback**: Have human review for critical or ambiguous cases

#### Detection Limitations

Be aware of system limitations:

- Detection accuracy varies by forgery type and quality
- Advanced AI-generated images may require specialized models
- Very small manipulations might be missed
- Results should be treated as probabilistic, not definitive
- System should be part of a broader verification strategy

## ğŸ¤ Contributing <a name="contributing"></a>

We welcome contributions to VerifyVision-Pro! Here's how you can help:

### Reporting Issues

- Use the GitHub issue tracker to report bugs
- Include detailed steps to reproduce the issue
- Attach sample images when relevant (ensure you have rights to share)
- Specify your environment (OS, Python version, etc.)

### Development Process

1. **Fork the repository**
2. **Create a feature branch**:
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **Make your changes**
4. **Run tests**:
   ```bash
   python -m pytest tests/
   ```
5. **Submit a pull request**

### Contribution Areas

We particularly welcome contributions in:

- **New Models**: Implementations of state-of-the-art architectures
- **Detection Methods**: Novel approaches to identifying manipulations
- **UI Improvements**: Enhancing the web interface and visualization
- **Performance Optimization**: Improving speed and resource usage
- **Documentation**: Tutorials, examples, and clarifications
- **Localization**: Translations of documentation and interface

### Code Style

Please follow these guidelines:

- PEP 8 compliant Python code
- Docstrings for all functions, classes, and modules
- Type hints where appropriate
- Comprehensive comments for complex logic
- Unit tests for new functionality

## ğŸ“„ License <a name="license"></a>

VerifyVision-Pro is released under the MIT License.

### MIT License

```
Copyright (c) 2025 VerifyVision-Pro Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### Third-Party Components

This project incorporates components from third-party open source projects:

- PyTorch (BSD License)
- Flask (BSD License)
- TorchVision (BSD License)
- OpenCV (Apache 2.0 License)
- Bootstrap (MIT License)
- Various other packages as listed in requirements.txt

---

<a name="chinese-documentation"></a>
# ä¸­æ–‡æ–‡æ¡£ ğŸŒ

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…](#å®‰è£…)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [Webåº”ç”¨](#webåº”ç”¨)
- [æŠ€æœ¯å®ç°](#æŠ€æœ¯å®ç°)
- [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å¸¸è§é—®é¢˜è§£å†³](#å¸¸è§é—®é¢˜è§£å†³)
- [æ³¨æ„äº‹é¡¹](#æ³¨æ„äº‹é¡¹)
- [å‚ä¸è´¡çŒ®](#å‚ä¸è´¡çŒ®)
- [è®¸å¯è¯](#è®¸å¯è¯)

## ğŸ”­ æ¦‚è¿° <a name="æ¦‚è¿°"></a>

VerifyVision-Proæ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒä¼ªé€ æ£€æµ‹ç³»ç»Ÿï¼Œèƒ½å¤Ÿé«˜ç²¾åº¦åœ°è¯†åˆ«å„ç§å›¾åƒç¯¡æ”¹ã€‚ç³»ç»Ÿé›†æˆäº†å¼ºå¤§çš„æ•°æ®å¤„ç†æµç¨‹ã€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œç›´è§‚çš„Webç•Œé¢ï¼Œå®ç°å®æ—¶æ£€æµ‹åŠŸèƒ½ã€‚

### ğŸŒŸ ä¸»è¦ç‰¹ç‚¹

- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šå®ç°å¤šç§æ¶æ„ï¼ˆEfficientNetã€ResNetã€Xceptionã€CNNï¼‰
- **å®Œæ•´æµç¨‹**ï¼šä»æ•°æ®å‡†å¤‡åˆ°éƒ¨ç½²çš„å…¨æµç¨‹è§£å†³æ–¹æ¡ˆ
- **ç”¨æˆ·å‹å¥½ç•Œé¢**ï¼šåŸºäºWebçš„ç•Œé¢ï¼Œä¾¿äºä¸ç³»ç»Ÿäº¤äº’
- **è¯¦ç»†åˆ†æ**ï¼šæä¾›ç½®ä¿¡åº¦è¯„åˆ†å’Œç»“æœå¯è§†åŒ–
- **ä¼˜åŒ–æ€§èƒ½**ï¼šæ”¯æŒCPUå’ŒGPUæ¨ç†åŠ é€Ÿ

## ğŸ“ é¡¹ç›®ç»“æ„ <a name="é¡¹ç›®ç»“æ„"></a>

```
VerifyVision-Pro/
â”‚
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ real/                  # çœŸå®å›¾åƒ
â”‚   â”œâ”€â”€ fake/                  # ä¼ªé€ å›¾åƒ
â”‚   â””â”€â”€ processed/             # é¢„å¤„ç†åçš„å›¾åƒ
â”‚
â”œâ”€â”€ models/                    # æ¨¡å‹ç›®å½•ï¼ˆå·²è¢«gitå¿½ç•¥ï¼‰
â”‚   â””â”€â”€ saved/                 # ä¿å­˜çš„æ¨¡å‹æƒé‡
â”‚
â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”œâ”€â”€ data_utils/            # æ•°æ®å¤„ç†å·¥å…·
â”‚   â”‚   â”œâ”€â”€ dataset.py         # æ•°æ®é›†ç±»
â”‚   â”‚   â””â”€â”€ data_processor.py  # æ•°æ®é¢„å¤„ç†å·¥å…·
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â””â”€â”€ models.py          # æ·±åº¦å­¦ä¹ æ¨¡å‹å®ç°
â”‚   â”‚
â”‚   â”œâ”€â”€ training/              # è®­ç»ƒç›¸å…³
â”‚   â”‚   â”œâ”€â”€ train.py           # è®­ç»ƒè„šæœ¬
â”‚   â”‚   â””â”€â”€ evaluate.py        # è¯„ä¼°è„šæœ¬
â”‚   â”‚
â”‚   â””â”€â”€ web/                   # Webåº”ç”¨
â”‚       â””â”€â”€ app.py             # Flaskåº”ç”¨
â”‚
â”œâ”€â”€ static/                    # é™æ€èµ„æº
â”‚   â”œâ”€â”€ css/                   # CSSæ ·å¼
â”‚   â”‚   â””â”€â”€ style.css          # è‡ªå®šä¹‰æ ·å¼
â”‚   â”‚
â”‚   â”œâ”€â”€ js/                    # JavaScript
â”‚   â”‚   â””â”€â”€ main.js            # ä¸»JSæ–‡ä»¶
â”‚   â”‚
â”‚   â””â”€â”€ uploads/               # ç”¨æˆ·ä¸Šä¼ çš„å›¾åƒ
â”‚
â”œâ”€â”€ templates/                 # HTMLæ¨¡æ¿
â”‚   â”œâ”€â”€ base.html              # åŸºç¡€æ¨¡æ¿
â”‚   â”œâ”€â”€ index.html             # é¦–é¡µ
â”‚   â”œâ”€â”€ result.html            # ç»“æœé¡µé¢
â”‚   â””â”€â”€ about.html             # å…³äºé¡µé¢
â”‚
â”œâ”€â”€ generate_test_images.py    # æµ‹è¯•å›¾åƒç”Ÿæˆè„šæœ¬
â”œâ”€â”€ main.py                    # é¡¹ç›®ä¸»å…¥å£ç¨‹åº
â”œâ”€â”€ requirements.txt           # é¡¹ç›®ä¾èµ–
â””â”€â”€ README.md                  # é¡¹ç›®è¯´æ˜
```

## ğŸ’» ç³»ç»Ÿè¦æ±‚ <a name="ç³»ç»Ÿè¦æ±‚"></a>

### æœ€ä½é…ç½®

- **Python**: 3.7+
- **PyTorch**: 2.0+
- **å†…å­˜**: 4GBï¼ˆä»…CPUï¼‰ï¼Œ8GBï¼ˆå¸¦GPUï¼‰
- **å­˜å‚¨**: ä»£ç å’ŒåŸºæœ¬æ•°æ®é›†éœ€è¦1GB
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.15+, Ubuntu 18.04+

### æ¨èé…ç½®

- **Python**: 3.9+
- **PyTorch**: 2.0+ï¼ˆå¸¦CUDAæ”¯æŒï¼‰
- **GPU**: NVIDIA GPUï¼Œæ”¯æŒCUDAï¼ˆ8GB+æ˜¾å­˜ï¼‰
- **å†…å­˜**: 16GB
- **å­˜å‚¨**: æ‰©å±•æ•°æ®é›†éœ€è¦10GB+
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04+æˆ–macOS 12+

## ğŸ“¦ å®‰è£… <a name="å®‰è£…"></a>

### æ­¥éª¤1ï¼šå…‹éš†ä»“åº“

```bash
git clone https://github.com/lintsinghua/VerifyVision-Pro.git
cd VerifyVision-Pro
```

### æ­¥éª¤2ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# macOS/Linux
python -m venv imgvenv
source imgvenv/bin/activate

# Windows
python -m venv imgvenv
imgvenv\Scripts\activate
```

### æ­¥éª¤3ï¼šå®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### æ­¥éª¤4ï¼šéªŒè¯å®‰è£…

```bash
# æ£€æŸ¥PyTorchæ˜¯å¦æ­£ç¡®å®‰è£…å¹¶æ”¯æŒCUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰
python -c "import torch; print('CUDAå¯ç”¨ï¼š', torch.cuda.is_available())"
```

### å¯é€‰ï¼šGPUé…ç½®

å¦‚æœæ‚¨æœ‰NVIDIA GPUï¼Œè¯·ç¡®ä¿å®‰è£…äº†ä¸æ‚¨çš„PyTorchç‰ˆæœ¬å…¼å®¹çš„CUDAå·¥å…·åŒ…å’ŒcuDNNã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹ <a name="å¿«é€Ÿå¼€å§‹"></a>

æŒ‰ç…§ä»¥ä¸‹æŒ‡å—å¿«é€Ÿè®¾ç½®å’Œè¿è¡ŒVerifyVision-Proç³»ç»Ÿï¼š

### æ­¥éª¤1ï¼šç”Ÿæˆæµ‹è¯•æ•°æ® ğŸ²

é¦–å…ˆï¼Œä¸ºç³»ç»Ÿæµ‹è¯•ç”Ÿæˆæ ·æœ¬å›¾åƒï¼š

```bash
python generate_test_images.py
```

è¿™å°†åœ¨ç›¸åº”çš„æ•°æ®ç›®å½•ä¸­åˆ›å»º20å¼ çœŸå®å›¾åƒå’Œ20å¼ ä¼ªé€ å›¾åƒã€‚

### æ­¥éª¤2ï¼šé¢„å¤„ç†å›¾åƒ ğŸ–Œï¸

å‡†å¤‡ç”¨äºæ¨¡å‹è®­ç»ƒçš„å›¾åƒï¼š

```bash
# å¤„ç†çœŸå®å›¾åƒ
python main.py preprocess --input-dir data/real --output-dir data/processed/real --target-size 224 224

# å¤„ç†ä¼ªé€ å›¾åƒ
python main.py preprocess --input-dir data/fake --output-dir data/processed/fake --target-size 224 224
```

### æ­¥éª¤3ï¼šè®­ç»ƒæ¨¡å‹ ğŸ§ 

ä½¿ç”¨é¢„å¤„ç†åçš„æ•°æ®è®­ç»ƒåŸºæœ¬CNNæ¨¡å‹ï¼š

```bash
python main.py train \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model cnn \
  --pretrained \
  --epochs 5 \
  --batch-size 4 \
  --save-dir models/saved
```

> **æ³¨æ„**ï¼šåˆå§‹æµ‹è¯•æ—¶ï¼Œå°‘é‡çš„epochsï¼ˆå¦‚5ï¼‰å°±è¶³å¤Ÿäº†ã€‚è‹¥è¦æé«˜æ€§èƒ½ï¼Œå¯å¢åŠ è®­ç»ƒå‘¨æœŸã€‚

### æ­¥éª¤4ï¼šå¯åŠ¨Webåº”ç”¨ ğŸŒ

å¯åŠ¨Webç•Œé¢ä»¥ä¸è®­ç»ƒå¥½çš„æ¨¡å‹äº¤äº’ï¼š

```bash
python main.py web \
  --model-path models/saved/best_model.pth \
  --model-name cnn \
  --port 8080 \
  --debug
```

> **é‡è¦**ï¼šåœ¨macOSä¸Šï¼Œç«¯å£5000å¯èƒ½è¢«AirPlayæœåŠ¡å ç”¨ï¼Œå»ºè®®ä½¿ç”¨ç«¯å£8080ã€‚

### æ­¥éª¤5ï¼šè®¿é—®åº”ç”¨ ğŸ–±ï¸

æ‰“å¼€æµè§ˆå™¨è®¿é—®[http://localhost:8080](http://localhost:8080)å³å¯ä½¿ç”¨ç³»ç»Ÿã€‚

## ğŸ“Š æ•°æ®å‡†å¤‡ <a name="æ•°æ®å‡†å¤‡"></a>

### è·å–æ•°æ®é›† ğŸ“¥

æœ‰å¤šç§æ–¹æ³•å¯ä»¥æ”¶é›†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼š

#### æ–¹æ³•1ï¼šæµ‹è¯•æ•°æ®ç”Ÿæˆï¼ˆæ¨èåˆå­¦è€…ä½¿ç”¨ï¼‰

å†…ç½®è„šæœ¬å¯ç”Ÿæˆç”¨äºæµ‹è¯•çš„åˆæˆæ•°æ®ï¼š

```bash
python generate_test_images.py
```

**åŠŸèƒ½è¯´æ˜ï¼š**
- åˆ›å»º`data/real`å’Œ`data/fake`ç›®å½•
- ç”Ÿæˆ20å¼ å…·æœ‰éšæœºå†…å®¹çš„çœŸå®å›¾åƒ
- åˆ›å»º20å¼ å¯¹åº”çš„ä¼ªé€ å›¾åƒ
- é€‚ç”¨äºåˆå§‹ç³»ç»Ÿæµ‹è¯•å’ŒéªŒè¯

#### æ–¹æ³•2ï¼šå…¬å¼€æ•°æ®é›†

è·å–å…³äºå…¬å¼€å›¾åƒä¼ªé€ æ£€æµ‹æ•°æ®é›†çš„ä¿¡æ¯ï¼š

```bash
python main.py download-info
```

è¿™ä¼šæ˜¾ç¤ºå›¾åƒä¼ªé€ æ£€æµ‹ç ”ç©¶ä¸­å¸¸ç”¨çš„æ•°æ®é›†é“¾æ¥ï¼ŒåŒ…æ‹¬ï¼š
- CASIA v1.0å’Œv2.0
- Columbiaå›¾åƒæ‹¼æ¥æ£€æµ‹
- CoMoFoDï¼ˆæ‹·è´-ç§»åŠ¨ä¼ªé€ æ•°æ®é›†ï¼‰
- Coverage
- IEEE IFS-TCå›¾åƒå–è¯æŒ‘æˆ˜æ•°æ®é›†

#### æ–¹æ³•3ï¼šè‡ªå®šä¹‰æ•°æ®é›†åˆ›å»º

é€šè¿‡ä»¥ä¸‹æ–¹æ³•æ„å»ºè‡ªå·±çš„æ•°æ®é›†ï¼š

1. **æ”¶é›†çœŸå®å›¾åƒ**ï¼š
   - å°†çœŸå®å›¾åƒæ”¾å…¥`data/real`ç›®å½•
   - ä½¿ç”¨ä¸ªäººç…§ç‰‡æˆ–å…¬å…±é¢†åŸŸå›¾åƒ
   - ç¡®ä¿å†…å®¹ã€å…‰çº¿æ¡ä»¶å’Œæ¥æºè®¾å¤‡å¤šæ ·åŒ–

2. **åˆ›å»ºä¼ªé€ å›¾åƒ**ï¼š
   ```bash
   python main.py create-fake \
     --real-dir data/real \
     --fake-dir data/fake \
     --method splice \
     --num-images 1000
   ```

**å¯ç”¨ä¼ªé€ æ–¹æ³•ï¼š**
- `splice`ï¼šç»„åˆæ¥è‡ªä¸åŒå›¾åƒçš„åŒºåŸŸ
- `copy`ï¼šå¤åˆ¶åŒä¸€å›¾åƒå†…çš„åŒºåŸŸ
- `noise`ï¼šæ·»åŠ å±€éƒ¨å™ªå£°ä»¥åˆ›å»ºä¸ä¸€è‡´
- `color`ï¼šåœ¨ç‰¹å®šåŒºåŸŸæ“ä½œé¢œè‰²å±æ€§

### é¢„å¤„ç†æ•°æ® ğŸ”„

è®­ç»ƒå‰ï¼Œéœ€è¦å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ä»¥ä¿æŒä¸€è‡´æ€§ï¼š

```bash
python main.py preprocess \
  --input-dir data/real \
  --output-dir data/processed/real \
  --target-size 224 224 \
  --max-images 5000
```

**é¢„å¤„ç†æ“ä½œåŒ…æ‹¬ï¼š**
- è°ƒæ•´ä¸ºç»Ÿä¸€å°ºå¯¸
- æ ‡å‡†åŒ–
- å¯é€‰çš„æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ç­‰ï¼‰
- æ ¼å¼æ ‡å‡†åŒ–
- å¯é€‰çš„è‰²å½©ç©ºé—´è½¬æ¢

**å‚æ•°è¯´æ˜ï¼š**
- `--input-dir`ï¼šæºå›¾åƒç›®å½•
- `--output-dir`ï¼šå¤„ç†åå›¾åƒçš„ç›®æ ‡ç›®å½•
- `--target-size`ï¼šè¾“å‡ºå°ºå¯¸ï¼ˆå®½åº¦ é«˜åº¦ï¼‰
- `--max-images`ï¼šé™åˆ¶å¤„ç†çš„å›¾åƒæ•°é‡ï¼ˆå¯é€‰ï¼‰
- `--augment`ï¼šåº”ç”¨æ•°æ®å¢å¼ºï¼ˆå¯é€‰ï¼‰

## ğŸ‹ï¸â€â™‚ï¸ æ¨¡å‹è®­ç»ƒ <a name="æ¨¡å‹è®­ç»ƒ"></a>

### ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹

VerifyVision-Proæ”¯æŒè®­ç»ƒå„ç§æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå›¾åƒä¼ªé€ æ£€æµ‹ï¼š

```bash
python main.py train \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model efficientnet_b0 \
  --pretrained \
  --epochs 30 \
  --batch-size 32 \
  --learning-rate 0.001 \
  --save-dir models/saved \
  --early-stopping \
  --patience 5
```

### å¯ç”¨æ¨¡å‹

ç³»ç»Ÿå®ç°äº†å¤šç§æœ€å…ˆè¿›çš„æ¶æ„ï¼š

| æ¨¡å‹ | æè¿° | å‚æ•°æ•°é‡ | é€‚ç”¨åœºæ™¯ |
|-------|-------------|------------|--------------|
| `cnn` | è‡ªå®šä¹‰CNN | ~500K | å¿«é€Ÿæµ‹è¯•ï¼Œæœ‰é™æ•°æ® |
| `resnet18` | ResNet-18 | ~11M | å°å‹åˆ°ä¸­å‹æ•°æ®é›† |
| `resnet50` | ResNet-50 | ~25M | ä¸­å‹æ•°æ®é›† |
| `efficientnet_b0` | EfficientNet-B0 | ~5M | å¹³è¡¡æ€§èƒ½ |
| `xception` | Xception | ~22M | é«˜çº§ç‰¹å¾ |

### è®­ç»ƒå‚æ•°

è®­ç»ƒæ¨¡å—æä¾›å…¨é¢çš„è‡ªå®šä¹‰é€‰é¡¹ï¼š

| å‚æ•° | æè¿° | é»˜è®¤å€¼ | å¤‡æ³¨ |
|-----------|-------------|---------|-------|
| `--real-dir` | çœŸå®å›¾åƒç›®å½• | - | å¿…éœ€ |
| `--fake-dir` | ä¼ªé€ å›¾åƒç›®å½• | - | å¿…éœ€ |
| `--model` | æ¨¡å‹æ¶æ„ | `efficientnet_b0` | æŸ¥çœ‹å¯ç”¨æ¨¡å‹ |
| `--pretrained` | ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ | `False` | æ ‡å¿— |
| `--epochs` | è®­ç»ƒå‘¨æœŸ | `30` | |
| `--batch-size` | æ‰¹æ¬¡å¤§å° | `32` | å‡å°ä»¥é™ä½å†…å­˜å ç”¨ |
| `--learning-rate` | å­¦ä¹ ç‡ | `0.001` | |
| `--weight-decay` | L2æ­£åˆ™åŒ– | `0.0001` | |
| `--save-dir` | ä¿å­˜ç›®å½• | `models/saved` | |
| `--early-stopping` | å¯ç”¨æ—©åœ | `False` | æ ‡å¿— |
| `--patience` | æ—©åœå‘¨æœŸæ•° | `5` | |
| `--validation-split` | éªŒè¯æ•°æ®æ¯”ä¾‹ | `0.2` | |

### è®­ç»ƒè¿‡ç¨‹

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿä¼šï¼š

1. å°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
2. åŠ è½½æˆ–åˆå§‹åŒ–æ‰€é€‰æ¨¡å‹æ¶æ„
3. å¦‚æœè¯·æ±‚äº†é¢„è®­ç»ƒæƒé‡ï¼Œåº”ç”¨è¿ç§»å­¦ä¹ 
4. ä½¿ç”¨æŒ‡å®šå­¦ä¹ ç‡çš„Adamä¼˜åŒ–å™¨è¿›è¡Œä¼˜åŒ–
5. å®ç°å­¦ä¹ ç‡è°ƒåº¦ä»¥è·å¾—æ›´å¥½çš„æ”¶æ•›æ€§
6. ç›‘æ§éªŒè¯æŒ‡æ ‡ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ
7. æ ¹æ®éªŒè¯ç²¾åº¦ä¿å­˜è¡¨ç°æœ€ä½³çš„æ¨¡å‹
8. ç”Ÿæˆè®­ç»ƒæ›²çº¿å’Œæ€§èƒ½ç»Ÿè®¡

### é«˜çº§è®­ç»ƒåŠŸèƒ½

- **æ—©åœ**ï¼šå½“æ€§èƒ½è¾¾åˆ°å¹³å°æœŸæ—¶è‡ªåŠ¨åœæ­¢è®­ç»ƒ
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šå½“è¿›åº¦åœæ»æ—¶é™ä½å­¦ä¹ ç‡
- **æ£€æŸ¥ç‚¹**ï¼šåœ¨è®­ç»ƒæœŸé—´å®šæœŸä¿å­˜æ¨¡å‹
- **æ··åˆç²¾åº¦**ï¼šåœ¨ç¡¬ä»¶æ”¯æŒæ—¶ä½¿ç”¨FP16è®­ç»ƒ
- **æ¢¯åº¦è£å‰ª**ï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **æ•°æ®å¢å¼º**ï¼šè®­ç»ƒæœŸé—´å¯é€‰çš„å®æ—¶å¢å¼º

## ğŸ“ æ¨¡å‹è¯„ä¼° <a name="æ¨¡å‹è¯„ä¼°"></a>

### è¯„ä¼°æ¨¡å‹æ€§èƒ½

è®­ç»ƒåï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼š

```bash
python main.py evaluate \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model efficientnet_b0 \
  --checkpoint models/saved/best_model.pth \
  --results-dir results \
  --confusion-matrix \
  --roc-curve
```

### è¯„ä¼°æŒ‡æ ‡

è¯„ä¼°æ¨¡å—æä¾›å…¨é¢çš„æ€§èƒ½æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | æè¿° | èŒƒå›´ |
|--------|-------------|-------|
| å‡†ç¡®ç‡ | æ€»ä½“æ­£ç¡®é¢„æµ‹æ¯”ä¾‹ | 0-1 |
| ç²¾ç¡®ç‡ | çœŸé˜³æ€§/é¢„æµ‹é˜³æ€§ | 0-1 |
| å¬å›ç‡ | çœŸé˜³æ€§/å®é™…é˜³æ€§ | 0-1 |
| F1åˆ†æ•° | ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ | 0-1 |
| AUC-ROC | ROCæ›²çº¿ä¸‹é¢ç§¯ | 0-1 |
| æ··æ·†çŸ©é˜µ | é¢„æµ‹ä¸çœŸå®å€¼çš„å¯è§†åŒ– | - |

### é«˜çº§è¯„ä¼°åŠŸèƒ½

- **åˆ†ç±»åˆ«åˆ†æ**ï¼šçœŸå®å’Œä¼ªé€ ç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡
- **ç½®ä¿¡åº¦åˆ†å¸ƒ**ï¼šé¢„æµ‹ç½®ä¿¡åº¦çš„ç›´æ–¹å›¾
- **å¤±è´¥åˆ†æ**ï¼šå¯¹é”™è¯¯åˆ†ç±»æ ·æœ¬çš„æ£€æŸ¥
- **ç‰¹å¾å¯è§†åŒ–**ï¼šæ˜¾ç¤ºå½±å“åŒºåŸŸçš„æ¿€æ´»å›¾
- **äº¤å‰éªŒè¯**ï¼šå¯é€‰çš„kæŠ˜äº¤å‰éªŒè¯ä»¥è·å¾—ç¨³å¥è¯„ä¼°

### è§£è¯»ç»“æœ

è¯„ä¼°ç»“æœæœ‰åŠ©äºç†è§£ï¼š

- æ¨¡å‹å¯¹æœªè§æ•°æ®çš„æ³›åŒ–èƒ½åŠ›
- æ¨¡å‹æ˜¯å¦åå‘ç‰¹å®šç±»åˆ«
- å¯¼è‡´æ£€æµ‹å¤±è´¥çš„å›¾åƒç±»å‹
- é¢„æµ‹çš„ç½®ä¿¡åº¦æ°´å¹³
- å¯èƒ½çš„æ”¹è¿›é¢†åŸŸ

## ğŸŒ Webåº”ç”¨ <a name="webåº”ç”¨"></a>

### å¯åŠ¨Webç•Œé¢

å¯åŠ¨Webåº”ç”¨ä»¥ä¸è®­ç»ƒå¥½çš„æ¨¡å‹äº¤äº’ï¼š

```bash
python main.py web \
  --model-path models/saved/best_model.pth \
  --model-name efficientnet_b0 \
  --port 8080 \
  --host 0.0.0.0 \
  --debug
```

### Webåº”ç”¨åŠŸèƒ½

VerifyVision-Proçš„Webç•Œé¢æä¾›ï¼š

- **ç”¨æˆ·å‹å¥½çš„ä¸Šä¼ **ï¼šç®€å•çš„æ‹–æ”¾æˆ–æ–‡ä»¶é€‰æ‹©ç•Œé¢
- **å®æ—¶åˆ†æ**ï¼šå³æ—¶å¤„ç†å’Œç»“æœæ˜¾ç¤º
- **è§†è§‰åé¦ˆ**ï¼šæ¸…æ™°æ˜¾ç¤ºçœŸä¼ªç»“æœå’Œç½®ä¿¡åº¦åˆ†æ•°
- **çƒ­åŠ›å›¾å¯è§†åŒ–**ï¼šå¯é€‰çš„å¯ç–‘åŒºåŸŸå¯è§†åŒ–
- **ç»“æœå†å²**ï¼šåŸºäºä¼šè¯çš„åˆ†æå›¾åƒå†å²
- **å“åº”å¼è®¾è®¡**ï¼šé€‚ç”¨äºæ¡Œé¢å’Œç§»åŠ¨è®¾å¤‡

### è®¾ç½®å‚æ•°

| å‚æ•° | æè¿° | é»˜è®¤å€¼ | å¤‡æ³¨ |
|-----------|-------------|---------|-------|
| `--model-path` | æ¨¡å‹æ–‡ä»¶è·¯å¾„ | - | å¿…éœ€ |
| `--model-name` | æ¨¡å‹æ¶æ„ | - | å¿…éœ€ |
| `--port` | æœåŠ¡å™¨ç«¯å£ | `5000` | macOSä¸Šä½¿ç”¨`8080` |
| `--host` | ä¸»æœºåœ°å€ | `127.0.0.1` | å¤–éƒ¨è®¿é—®ä½¿ç”¨`0.0.0.0` |
| `--debug` | å¯ç”¨è°ƒè¯•æ¨¡å¼ | `False` | æ ‡å¿— |
| `--max-size` | æœ€å¤§ä¸Šä¼ å¤§å°(MB) | `5` | |
| `--threshold` | æ£€æµ‹é˜ˆå€¼ | `0.5` | èŒƒå›´ï¼š0-1 |

### ä½¿ç”¨Webåº”ç”¨ ğŸ’»

1. **ä¸Šä¼ å›¾åƒ**ï¼š
   - ç‚¹å‡»"é€‰æ‹©æ–‡ä»¶"æˆ–å°†å›¾åƒæ‹–æ”¾åˆ°ä¸Šä¼ åŒºåŸŸ
   - æ”¯æŒçš„æ ¼å¼ï¼šJPGã€JPEGã€PNG
   - æœ€å¤§æ–‡ä»¶å¤§å°ï¼š5MBï¼ˆå¯é…ç½®ï¼‰

2. **åˆ†æå›¾åƒ**ï¼š
   - ç‚¹å‡»"ä¸Šä¼ å¹¶æ£€æµ‹"æŒ‰é’®
   - ç³»ç»Ÿé€šè¿‡æ¨¡å‹å¤„ç†å›¾åƒ

3. **æŸ¥çœ‹ç»“æœ**ï¼š
   - æ˜¾ç¤ºçœŸå®/ä¼ªé€ åˆ†ç±»ç»“æœ
   - ç½®ä¿¡åº¦åˆ†æ•°è¡¨ç¤ºæ£€æµ‹ç¡®å®šæ€§
   - å¯é€‰çš„çƒ­åŠ›å›¾å¯è§†åŒ–çªå‡ºæ˜¾ç¤ºå¯ç–‘åŒºåŸŸ
   - é™„åŠ å…ƒæ•°æ®æ˜¾ç¤ºå›¾åƒå±æ€§

4. **è§£è¯»ç»“æœ**ï¼š
   - æ›´é«˜çš„ç½®ä¿¡åº¦åˆ†æ•°è¡¨ç¤ºæ›´å¤§çš„ç¡®å®šæ€§
   - æ¥è¿‘0.5çš„åˆ†æ•°è¡¨ç¤ºä¸ç¡®å®šæ€§
   - å¯¹äºæ¨¡ç³Šçš„æƒ…å†µï¼Œè€ƒè™‘ä½¿ç”¨å¤šä¸ªæ¨¡å‹

### éƒ¨ç½²é€‰é¡¹

å¯¹äºç”Ÿäº§éƒ¨ç½²ï¼Œè€ƒè™‘ä»¥ä¸‹æ–¹æ¡ˆï¼š

- **Nginx/Apache**ï¼šè®¾ç½®åå‘ä»£ç†ä»¥æé«˜å®‰å…¨æ€§å’Œæ€§èƒ½
- **Docker**ï¼šå®¹å™¨åŒ–éƒ¨ç½²ä»¥ä¿æŒç¯å¢ƒä¸€è‡´æ€§
- **äº‘å¹³å°**ï¼šAWSã€Google Cloudæˆ–Azureä»¥å®ç°å¯æ‰©å±•æ€§
- **SSLè¯ä¹¦**ï¼šå¯ç”¨HTTPSä»¥è¿›è¡Œå®‰å…¨é€šä¿¡
- **è®¿é—®é™åˆ¶**ï¼šé˜²æ­¢æœåŠ¡æ»¥ç”¨

## ğŸ”§ æŠ€æœ¯å®ç° <a name="æŠ€æœ¯å®ç°"></a>

### æ ¸å¿ƒæŠ€æœ¯

VerifyVision-ProåŸºäºç°ä»£æŠ€æœ¯æ„å»ºï¼Œä»¥å®ç°å¯é çš„æ€§èƒ½ï¼š

#### æ•°æ®å¤„ç†
- **OpenCV**ï¼šå›¾åƒåŠ è½½ã€é¢„å¤„ç†å’Œæ“ä½œ
- **PIL (Pillow)**ï¼šå›¾åƒæ ¼å¼å¤„ç†å’Œè½¬æ¢
- **Albumentations**ï¼šé«˜çº§æ•°æ®å¢å¼ºæµç¨‹
- **NumPy**ï¼šå›¾åƒæ•°æ®çš„é«˜æ•ˆæ•°å€¼è¿ç®—

#### æ·±åº¦å­¦ä¹ æ¡†æ¶
- **PyTorch**ï¼šä¸»è¦æ·±åº¦å­¦ä¹ æ¡†æ¶
- **TorchVision**ï¼šé¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†å®ç”¨å·¥å…·
- **CUDA**ï¼šç”¨äºè®­ç»ƒå’Œæ¨ç†çš„GPUåŠ é€Ÿ
- **torchinfo**ï¼šæ¨¡å‹æ¶æ„å¯è§†åŒ–å’Œåˆ†æ

#### æ¨¡å‹æ¶æ„
- **EfficientNet**ï¼šèµ„æºé«˜æ•ˆçš„å·ç§¯æ¶æ„
- **ResNet**ï¼šå¸¦è·³è·ƒè¿æ¥çš„æ·±åº¦æ®‹å·®ç½‘ç»œ
- **Xception**ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯ä»¥æé«˜æ•ˆç‡
- **è‡ªå®šä¹‰CNN**ï¼šç”¨äºåŸºæœ¬æ£€æµ‹çš„è½»é‡çº§æ¶æ„

#### Webæ¡†æ¶
- **Flask**ï¼šè½»é‡çº§WebæœåŠ¡å™¨å®ç°
- **Werkzeug**ï¼šWebåº”ç”¨çš„WSGIå®ç”¨å·¥å…·åº“
- **Jinja2**ï¼šHTMLç”Ÿæˆçš„æ¨¡æ¿å¼•æ“
- **Flask-WTF**ï¼šè¡¨å•å¤„ç†å’ŒéªŒè¯

#### å‰ç«¯
- **Bootstrap**ï¼šå“åº”å¼è®¾è®¡æ¡†æ¶
- **JavaScript**ï¼šåŠ¨æ€å®¢æˆ·ç«¯åŠŸèƒ½
- **Chart.js**ï¼šç»“æœçš„äº¤äº’å¼å¯è§†åŒ–
- **Dropzone.js**ï¼šå¢å¼ºçš„æ–‡ä»¶ä¸Šä¼ ä½“éªŒ

### å®ç°ç»†èŠ‚

#### æ¨¡å‹æ¶æ„è®¾è®¡

ç³»ç»Ÿå®ç°äº†ä¸¤ç±»åˆ†ç±»æ–¹æ³•ï¼ŒåŒ…å«ï¼š

- **ç‰¹å¾æå–**ï¼šå·ç§¯å±‚æ•è·ç©ºé—´ç‰¹å¾
- **ç‰¹å¾èšåˆ**ï¼šæ± åŒ–æ“ä½œèšåˆå±€éƒ¨ä¿¡æ¯
- **åˆ†ç±»å¤´**ï¼šå…¨è¿æ¥å±‚ç”¨äºæœ€ç»ˆé¢„æµ‹
- **è¿ç§»å­¦ä¹ **ï¼šé¢„è®­ç»ƒç½‘ç»œçš„é€‚åº”
- **é¢†åŸŸç‰¹å®šç‰¹å¾**ï¼šç”¨äºä¼ªé€ æ£€æµ‹çš„è‡ªå®šä¹‰å±‚

#### è®­ç»ƒæµç¨‹

è®­ç»ƒç³»ç»Ÿå®ç°ï¼š

- **æ•°æ®é›†ç®¡ç†**ï¼šè‡ªå®šä¹‰PyTorchæ•°æ®é›†ç”¨äºé«˜æ•ˆåŠ è½½
- **å¹³è¡¡é‡‡æ ·**ï¼šç¡®ä¿ç±»åˆ«å¹³ç­‰è¡¨ç¤º
- **å¢å¼ºç­–ç•¥**ï¼šåœ¨è®­ç»ƒæœŸé—´åº”ç”¨ä»¥æé«˜é²æ£’æ€§
- **æ··åˆç²¾åº¦**ï¼šåœ¨æ”¯æŒçš„æƒ…å†µä¸‹ä½¿ç”¨FP16åŠ é€Ÿè®­ç»ƒ
- **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šå¯é€‰çš„å¤šGPUæ”¯æŒ

#### æ¨ç†æµç¨‹

æ¨ç†ç³»ç»ŸåŒ…æ‹¬ï¼š

- **é¢„å¤„ç†**ï¼šä¸è®­ç»ƒæµç¨‹ä¸€è‡´
- **æ‰¹å¤„ç†**ï¼šé«˜æ•ˆå¤„ç†å¤šä¸ªå›¾åƒ
- **æ¨¡å‹é›†æˆ**ï¼šå¯é€‰çš„å¤šæ¨¡å‹ç»„åˆ
- **åå¤„ç†**ï¼šç½®ä¿¡åº¦æ ¡å‡†å’Œé˜ˆå€¼å¤„ç†
- **å¯è§†åŒ–**ï¼šç”Ÿæˆè§£é‡Šæ€§çƒ­åŠ›å›¾

## ğŸ”¬ é«˜çº§ç”¨æ³• <a name="é«˜çº§ç”¨æ³•"></a>

### è‡ªå®šä¹‰æ¨¡å‹å¼€å‘

é€šè¿‡è‡ªå®šä¹‰æ¨¡å‹æ¶æ„æ‰©å±•VerifyVision-Proï¼š

1. **æ·»åŠ æ–°æ¨¡å‹**ï¼š
   
   ä¿®æ”¹`src/models/models.py`ä»¥åŒ…æ‹¬æ‚¨çš„æ¶æ„ï¼š

   ```python
   class CustomModel(nn.Module):
       def __init__(self, num_classes=2, pretrained=False):
           super(CustomModel, self).__init__()
           # å®šä¹‰æ‚¨çš„æ¨¡å‹æ¶æ„
           
       def forward(self, x):
           # å®šä¹‰å‰å‘ä¼ æ’­
           return x
   ```

2. **æ³¨å†Œæ¨¡å‹**ï¼š
   
   å°†æ‚¨çš„æ¨¡å‹æ·»åŠ åˆ°æ¨¡å‹å·¥å‚ï¼š

   ```python
   def get_model(name, num_classes=2, pretrained=False):
       models = {
           # ç°æœ‰æ¨¡å‹
           'custom_model': CustomModel,
       }
       return models[name](num_classes=num_classes, pretrained=pretrained)
   ```

3. **ä½¿ç”¨æ‚¨çš„æ¨¡å‹**ï¼š
   
   ```bash
   python main.py train \
     --real-dir data/processed/real \
     --fake-dir data/processed/fake \
     --model custom_model \
     --epochs 30
   ```

### é«˜çº§æ•°æ®é›†æŠ€æœ¯

é€šè¿‡é«˜çº§æ•°æ®é›†å¤„ç†å¢å¼ºæ¨¡å‹æ€§èƒ½ï¼š

#### åˆæˆæ•°æ®ç”Ÿæˆ

ä½¿ç”¨ç”Ÿæˆæ–¹æ³•åˆ›å»ºé¢å¤–çš„è®­ç»ƒæ•°æ®ï¼š

```bash
python main.py generate-synthetic \
  --base-images data/real \
  --output-dir data/synthetic \
  --count 1000 \
  --techniques "copy,splice,removal,noise"
```

#### è·¨æ•°æ®é›†éªŒè¯

æµ‹è¯•æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†é—´çš„æ³›åŒ–èƒ½åŠ›ï¼š

```bash
python main.py cross-validate \
  --train-real data/datasetA/real \
  --train-fake data/datasetA/fake \
  --test-real data/datasetB/real \
  --test-fake data/datasetB/fake \
  --model efficientnet_b0
```

#### ä¸»åŠ¨å­¦ä¹ 

å®ç°ä¸»åŠ¨å­¦ä¹ ä»¥ä¼˜å…ˆæ ‡æ³¨åŠªåŠ›ï¼š

```bash
python main.py active-learning \
  --unlabeled data/unlabeled \
  --labeled data/labeled \
  --model-path models/saved/model.pth \
  --selection-method "entropy" \
  --batch-size 100
```

### æ¨¡å‹è§£é‡Š

é€šè¿‡é«˜çº§å¯è§†åŒ–ç†è§£æ¨¡å‹å†³ç­–ï¼š

```bash
python main.py interpret \
  --image path/to/image.jpg \
  --model-path models/saved/model.pth \
  --method "gradcam" \
  --output-dir visualizations
```

å¯ç”¨çš„è§£é‡Šæ–¹æ³•ï¼š
- `gradcam`ï¼šæ¢¯åº¦åŠ æƒç±»æ¿€æ´»æ˜ å°„
- `lime`ï¼šå±€éƒ¨å¯è§£é‡Šçš„æ¨¡å‹ä¸å¯çŸ¥è§£é‡Š
- `shap`ï¼šShapleyåŠ æ€§è§£é‡Š
- `occlusion`ï¼šé®æŒ¡æ•æ„Ÿæ€§åˆ†æ

## âš¡ æ€§èƒ½ä¼˜åŒ– <a name="æ€§èƒ½ä¼˜åŒ–"></a>

### ç¡¬ä»¶åŠ é€Ÿ

é€šè¿‡ç¡¬ä»¶ä¼˜åŒ–æœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½ï¼š

#### GPUåŠ é€Ÿ

å¯ç”¨GPUåŠ é€Ÿä»¥å®ç°æ›´å¿«çš„è®­ç»ƒå’Œæ¨ç†ï¼š

```bash
# æ£€æŸ¥GPUå¯ç”¨æ€§
python -c "import torch; print(torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'æ— GPU')"

# ä½¿ç”¨GPUè®­ç»ƒï¼ˆå¦‚æœå¯ç”¨åˆ™è‡ªåŠ¨ä½¿ç”¨ï¼‰
python main.py train --model efficientnet_b0 --batch-size 64 --real-dir data/processed/real --fake-dir data/processed/fake
```

#### å¤šGPUè®­ç»ƒ

å°†è®­ç»ƒåˆ†å¸ƒåˆ°å¤šä¸ªGPUä¸Šä»¥å¤„ç†æ›´å¤§çš„æ¨¡å‹ï¼š

```bash
python -m torch.distributed.launch --nproc_per_node=4 main.py train \
  --distributed \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake \
  --model efficientnet_b0 \
  --batch-size 128
```

#### CPUä¼˜åŒ–

åœ¨GPUä¸å¯ç”¨æ—¶ä¼˜åŒ–CPUæ€§èƒ½ï¼š

```bash
# è®¾ç½®CPUçº¿ç¨‹æ•°
python main.py train --num-workers 8 --pin-memory --real-dir data/processed/real --fake-dir data/processed/fake
```

### å†…å­˜ä¼˜åŒ–

ç®¡ç†å†…å­˜ä½¿ç”¨ä»¥å®ç°é«˜æ•ˆå¤„ç†ï¼š

#### æ‰¹å¤§å°è°ƒæ•´

æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´æ‰¹å¤§å°ï¼š

| ç¡¬ä»¶ | æ¨èæ‰¹å¤§å° |
|----------|------------------------|
| CPU | 8-16 |
| GPU 4GBæ˜¾å­˜ | 16-32 |
| GPU 8GBæ˜¾å­˜ | 32-64 |
| GPU 16GB+æ˜¾å­˜ | 64-128 |

```bash
# å†…å­˜æœ‰é™æ—¶ä½¿ç”¨è¾ƒå°æ‰¹å¤§å°
python main.py train --batch-size 8 --real-dir data/processed/real --fake-dir data/processed/fake

# é«˜ç«¯ç³»ç»Ÿä½¿ç”¨è¾ƒå¤§æ‰¹å¤§å°
python main.py train --batch-size 128 --real-dir data/processed/real --fake-dir data/processed/fake
```

#### æ¢¯åº¦ç´¯ç§¯

åœ¨æœ‰é™å†…å­˜ä¸Šä½¿ç”¨å¤§çš„æœ‰æ•ˆæ‰¹å¤§å°è¿›è¡Œè®­ç»ƒï¼š

```bash
python main.py train \
  --batch-size 16 \
  --gradient-accumulation 4 \
  --real-dir data/processed/real \
  --fake-dir data/processed/fake
```

è¿™æ¨¡æ‹Ÿäº†64ï¼ˆ16 Ã— 4ï¼‰çš„æ‰¹å¤§å°ï¼Œä½†åªéœ€è¦16ä¸ªæ ·æœ¬çš„å†…å­˜ã€‚

### æ¨ç†ä¼˜åŒ–

åŠ é€Ÿç”Ÿäº§éƒ¨ç½²ï¼š

#### æ¨¡å‹é‡åŒ–

å‡å°‘æ¨¡å‹å¤§å°å¹¶æé«˜æ¨ç†é€Ÿåº¦ï¼š

```bash
python main.py quantize \
  --model-path models/saved/best_model.pth \
  --quantized-model-path models/saved/quantized_model.pth \
  --calibration-images data/processed/real
```

è¿™å¯å°†æ¨¡å‹å¤§å°å‡å°‘é«˜è¾¾75%ï¼Œå¹¶å°†æ¨ç†é€Ÿåº¦æé«˜2-4å€ã€‚

#### æ‰¹é‡æ¨ç†

åŒæ—¶å¤„ç†å¤šä¸ªå›¾åƒï¼š

```bash
python main.py batch-inference \
  --input-dir data/test \
  --output-file results.csv \
  --model-path models/saved/best_model.pth \
  --batch-size 32
```

#### æ¨¡å‹å‰ªæ

ç§»é™¤ä¸å¿…è¦çš„è¿æ¥ä»¥åŠ å¿«æ¨ç†ï¼š

```bash
python main.py prune \
  --model-path models/saved/best_model.pth \
  --pruned-model-path models/saved/pruned_model.pth \
  --prune-ratio 0.3
```

## ğŸ”¨ å¸¸è§é—®é¢˜è§£å†³ <a name="å¸¸è§é—®é¢˜è§£å†³"></a>

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

æœ¬èŠ‚è§£å†³å¸¸è§é—®é¢˜ï¼š

#### ğŸ”„ å®‰è£…é—®é¢˜

##### CUDAå…¼å®¹æ€§é—®é¢˜

**ç—‡çŠ¶**ï¼šPyTorchå®‰è£…æˆåŠŸä½†CUDAæœªè¢«æ£€æµ‹åˆ°ï¼Œæˆ–åœ¨GPUæ“ä½œæœŸé—´å´©æºƒã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®ä¿ç‰ˆæœ¬å…¼å®¹ï¼š
   ```bash
   # æ£€æŸ¥CUDAç‰ˆæœ¬
   nvcc --version
   
   # å®‰è£…å…¼å®¹çš„PyTorchç‰ˆæœ¬
   pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html
   ```

2. éªŒè¯å®‰è£…ï¼š
   ```bash
   python -c "import torch; print('CUDAå¯ç”¨ï¼š', torch.cuda.is_available())"
   ```

##### åŒ…ä¾èµ–å†²çª

**ç—‡çŠ¶**ï¼š`pip install`å› ä¾èµ–å†²çªè€Œå¤±è´¥ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒï¼š
   ```bash
   python -m venv fresh_env
   source fresh_env/bin/activate
   ```

2. é€ä¸ªå®‰è£…ä¾èµ–ï¼š
   ```bash
   pip install numpy
   pip install torch torchvision
   pip install -r requirements.txt
   ```

#### ğŸ–¥ï¸ è¿è¡Œæ—¶é—®é¢˜

##### macOSä¸Šçš„ç«¯å£å ç”¨

**ç—‡çŠ¶**ï¼šWebåº”ç”¨å¯åŠ¨å¤±è´¥ï¼Œæç¤º"åœ°å€å·²è¢«ä½¿ç”¨"é”™è¯¯ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨ä¸åŒç«¯å£ï¼š
   ```bash
   python main.py web --model-path models/saved/best_model.pth --model-name cnn --port 8080
   ```

2. æˆ–æ‰¾åˆ°å¹¶ç»ˆæ­¢ä½¿ç”¨ç«¯å£5000çš„è¿›ç¨‹ï¼š
   ```bash
   sudo lsof -i :5000
   kill -9 <PID>
   ```

##### å†…å­˜æº¢å‡º(OOM)é”™è¯¯

**ç—‡çŠ¶**ï¼šè®­ç»ƒå´©æºƒï¼Œå‡ºç°"CUDAå†…å­˜ä¸è¶³"æˆ–ç³»ç»Ÿå†…å­˜é”™è¯¯ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡å°æ‰¹å¤§å°ï¼š
   ```bash
   python main.py train --batch-size 4 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š
   ```bash
   python main.py train --batch-size 2 --gradient-accumulation 8 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼š
   ```bash
   python main.py train --model resnet18 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

##### æ•°æ®é›†ä¸ºç©ºé”™è¯¯

**ç—‡çŠ¶**ï¼šè®­ç»ƒå¤±è´¥ï¼Œæç¤º"æ•°æ®é›†ä¸ºç©º"é”™è¯¯ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. éªŒè¯ç›®å½•è·¯å¾„ï¼š
   ```bash
   ls -la data/processed/real data/processed/fake
   ```

2. æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼ˆåº”ä¸º.jpgã€.jpegæˆ–.pngï¼‰ï¼š
   ```bash
   find data/processed/real -type f | grep -v -E '\.(jpg|jpeg|png)$'
   ```

3. ç”Ÿæˆæµ‹è¯•æ•°æ®ä»¥éªŒè¯ç³»ç»Ÿï¼š
   ```bash
   python generate_test_images.py
   ```

#### ğŸ‹ï¸â€â™‚ï¸ è®­ç»ƒé—®é¢˜

##### æ¨¡å‹æ€§èƒ½ä¸ä½³

**ç—‡çŠ¶**ï¼šæ¨¡å‹å‡†ç¡®ç‡ä½æˆ–è®­ç»ƒæœŸé—´æ²¡æœ‰æ”¹å–„ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å¢åŠ è®­ç»ƒæ—¶é•¿ï¼š
   ```bash
   python main.py train --epochs 50 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. å°è¯•ä¸åŒæ¨¡å‹ï¼š
   ```bash
   python main.py train --model efficientnet_b0 --pretrained --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. ç¡®ä¿æ•°æ®é›†å¹³è¡¡ï¼š
   ```bash
   python main.py analyze-dataset --real-dir data/processed/real --fake-dir data/processed/fake
   ```

4. å¯ç”¨æ•°æ®å¢å¼ºï¼š
   ```bash
   python main.py train --augmentation --real-dir data/processed/real --fake-dir data/processed/fake
   ```

##### è®­ç»ƒå¹³å°æœŸ

**ç—‡çŠ¶**ï¼šéªŒè¯å‡†ç¡®ç‡åœ¨è®­ç»ƒæ—©æœŸåœæ­¢æ”¹å–„ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. è°ƒæ•´å­¦ä¹ ç‡ï¼š
   ```bash
   python main.py train --learning-rate 0.0001 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. å®ç°å­¦ä¹ ç‡è°ƒåº¦ï¼š
   ```bash
   python main.py train --scheduler cosine --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. å°è¯•ä¸åŒä¼˜åŒ–å™¨ï¼š
   ```bash
   python main.py train --optimizer adamw --real-dir data/processed/real --fake-dir data/processed/fake
   ```

##### è¿‡æ‹Ÿåˆ

**ç—‡çŠ¶**ï¼šè®­ç»ƒå‡†ç¡®ç‡é«˜ä½†éªŒè¯å‡†ç¡®ç‡ä½ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ·»åŠ æ­£åˆ™åŒ–ï¼š
   ```bash
   python main.py train --weight-decay 0.001 --dropout 0.3 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

2. ä½¿ç”¨æ—©åœï¼š
   ```bash
   python main.py train --early-stopping --patience 5 --real-dir data/processed/real --fake-dir data/processed/fake
   ```

3. å¢åŠ æ•°æ®é›†å¤§å°æˆ–å¤šæ ·æ€§ã€‚

## ğŸ“ æ³¨æ„äº‹é¡¹ <a name="æ³¨æ„äº‹é¡¹"></a>

### å®ç”¨å»ºè®®

#### æ•°æ®é›†è´¨é‡

è®­ç»ƒæ•°æ®çš„è´¨é‡ç›´æ¥å½±å“æ¨¡å‹æ€§èƒ½ï¼š

- **è§„æ¨¡**ï¼šè‰¯å¥½æ€§èƒ½è‡³å°‘éœ€è¦æ¯ç±»1,000+å›¾åƒ
- **å¹³è¡¡**ï¼šä¿æŒçœŸå®å’Œä¼ªé€ å›¾åƒæ•°é‡ç›¸ç­‰
- **å¤šæ ·æ€§**ï¼šåŒ…æ‹¬å„ç§å›¾åƒæ¥æºã€å…‰ç…§æ¡ä»¶å’Œå†…å®¹
- **çœŸå®æ€§**ï¼šç¡®ä¿"çœŸå®"å›¾åƒç¡®å®æœªç»å¤„ç†
- **çœŸå®æ„Ÿ**ï¼šåˆ›å»ºä»£è¡¨ç°å®æ“ä½œæ–¹æ³•çš„ä¼ªé€ å›¾åƒ
- **å…ƒæ•°æ®**ï¼šä¿ç•™ç›¸å…³å…ƒæ•°æ®ï¼ˆç›¸æœºå‹å·ã€ç¼–è¾‘è½¯ä»¶ç­‰ï¼‰

#### æ¨¡å‹é€‰æ‹©

æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚é€‰æ‹©æ¨¡å‹ï¼š

| ä¼˜å…ˆè€ƒè™‘ | æ¨èæ¨¡å‹ |
|----------|-------------------|
| é€Ÿåº¦ | `cnn`æˆ–`resnet18` |
| å‡†ç¡®ç‡ | `efficientnet_b0`æˆ–`xception` |
| å¹³è¡¡æ€§èƒ½ | `resnet18`æˆ–`efficientnet_b0` |
| æœ‰é™æ•°æ® | `cnn`é…åˆå¤§é‡å¢å¼º |
| ç”Ÿäº§ç¯å¢ƒ | å¤šä¸ªæ¨¡å‹çš„é›†æˆ |

#### éƒ¨ç½²è€ƒè™‘å› ç´ 

å¯¹äºå®é™…éƒ¨ç½²ï¼š

- **å®‰å…¨æ€§**ï¼šå®æ–½é€Ÿç‡é™åˆ¶å’Œæ–‡ä»¶éªŒè¯
- **å¯æ‰©å±•æ€§**ï¼šå¯¹é«˜æµé‡åº”ç”¨ä½¿ç”¨è´Ÿè½½å‡è¡¡
- **éšç§**ï¼šè€ƒè™‘æ•æ„Ÿææ–™çš„æœ¬åœ°å¤„ç†
- **é€æ˜åº¦**ï¼šä¼ è¾¾ç½®ä¿¡æ°´å¹³å’Œå±€é™æ€§
- **æ›´æ–°**ï¼šå®šæœŸç”¨æ–°çš„ä¼ªé€ æŠ€æœ¯é‡æ–°è®­ç»ƒ
- **å¤‡é€‰æ–¹æ¡ˆ**ï¼šå¯¹å…³é”®æˆ–æ¨¡ç³Šæƒ…å†µæœ‰äººå·¥å®¡æ ¸

#### æ£€æµ‹å±€é™æ€§

äº†è§£ç³»ç»Ÿå±€é™æ€§ï¼š

- æ£€æµ‹å‡†ç¡®ç‡å› ä¼ªé€ ç±»å‹å’Œè´¨é‡è€Œå¼‚
- é«˜çº§AIç”Ÿæˆå›¾åƒå¯èƒ½éœ€è¦ä¸“é—¨æ¨¡å‹
- éå¸¸å°çš„æ“ä½œå¯èƒ½è¢«å¿½ç•¥
- ç»“æœåº”è¢«è§†ä¸ºæ¦‚ç‡æ€§çš„ï¼Œè€Œéç¡®å®šæ€§çš„
- ç³»ç»Ÿåº”ä½œä¸ºæ›´å¹¿æ³›éªŒè¯ç­–ç•¥çš„ä¸€éƒ¨åˆ†

## ğŸ¤ å‚ä¸è´¡çŒ® <a name="å‚ä¸è´¡çŒ®"></a>

æˆ‘ä»¬æ¬¢è¿å¯¹VerifyVision-Proçš„è´¡çŒ®ï¼ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å¸®åŠ©çš„æ–¹å¼ï¼š

### æŠ¥å‘Šé—®é¢˜

- ä½¿ç”¨GitHub issueè·Ÿè¸ªå™¨æŠ¥å‘Šbug
- åŒ…æ‹¬è¯¦ç»†çš„æ­¥éª¤ä»¥é‡ç°é—®é¢˜
- å¿…è¦æ—¶é™„åŠ æ ·æœ¬å›¾åƒï¼ˆç¡®ä¿æ‚¨æœ‰æƒå…±äº«ï¼‰
- æŒ‡å®šæ‚¨çš„ç¯å¢ƒï¼ˆæ“ä½œç³»ç»Ÿã€Pythonç‰ˆæœ¬ç­‰ï¼‰

### å¼€å‘æµç¨‹

1. **Forkä»“åº“**
2. **åˆ›å»ºç‰¹æ€§åˆ†æ”¯**ï¼š
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **åšå‡ºæ›´æ”¹**
4. **è¿è¡Œæµ‹è¯•**ï¼š
   ```bash
   python -m pytest tests/
   ```
5. **æäº¤æ‹‰å–è¯·æ±‚**

### è´¡çŒ®é¢†åŸŸ

æˆ‘ä»¬ç‰¹åˆ«æ¬¢è¿ä»¥ä¸‹é¢†åŸŸçš„è´¡çŒ®ï¼š

- **æ–°æ¨¡å‹**ï¼šæœ€å…ˆè¿›æ¶æ„çš„å®ç°
- **æ£€æµ‹æ–¹æ³•**ï¼šè¯†åˆ«æ“ä½œçš„æ–°æ–¹æ³•
- **UIæ”¹è¿›**ï¼šå¢å¼ºWebç•Œé¢å’Œå¯è§†åŒ–
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæé«˜é€Ÿåº¦å’Œèµ„æºä½¿ç”¨
- **æ–‡æ¡£**ï¼šæ•™ç¨‹ã€ç¤ºä¾‹å’Œè¯´æ˜
- **æœ¬åœ°åŒ–**ï¼šæ–‡æ¡£å’Œç•Œé¢çš„ç¿»è¯‘

### ä»£ç é£æ ¼

è¯·éµå¾ªä»¥ä¸‹å‡†åˆ™ï¼š

- ç¬¦åˆPEP 8çš„Pythonä»£ç 
- æ‰€æœ‰å‡½æ•°ã€ç±»å’Œæ¨¡å—çš„æ–‡æ¡£å­—ç¬¦ä¸²
- é€‚å½“çš„ç±»å‹æç¤º
- å¤æ‚é€»è¾‘çš„å…¨é¢æ³¨é‡Š
- æ–°åŠŸèƒ½çš„å•å…ƒæµ‹è¯•

## ğŸ“„ è®¸å¯è¯ <a name="è®¸å¯è¯"></a>

VerifyVision-Proåœ¨MITè®¸å¯è¯ä¸‹å‘å¸ƒã€‚

### MITè®¸å¯è¯

```
ç‰ˆæƒæ‰€æœ‰ (c) 2025 VerifyVision-Proè´¡çŒ®è€…

ç‰¹æ­¤æˆäºˆå…è´¹è®¸å¯ï¼Œä»»ä½•è·å¾—æœ¬è½¯ä»¶å’Œç›¸å…³æ–‡æ¡£æ–‡ä»¶ï¼ˆ"è½¯ä»¶"ï¼‰å‰¯æœ¬çš„äººï¼Œ
ä¸å—é™åˆ¶åœ°å¤„ç†æœ¬è½¯ä»¶ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€
åˆ†å‘ã€å†è®¸å¯å’Œ/æˆ–å‡ºå”®è½¯ä»¶å‰¯æœ¬çš„æƒåˆ©ï¼Œå¹¶å…è®¸å‘å…¶æä¾›è½¯ä»¶çš„äººè¿™æ ·åšï¼Œ
ä½†é¡»ç¬¦åˆä»¥ä¸‹æ¡ä»¶ï¼š

ä¸Šè¿°ç‰ˆæƒå£°æ˜å’Œæœ¬è®¸å¯å£°æ˜åº”åŒ…å«åœ¨è½¯ä»¶çš„æ‰€æœ‰å‰¯æœ¬æˆ–ä¸»è¦éƒ¨åˆ†ä¸­ã€‚

æœ¬è½¯ä»¶æŒ‰"åŸæ ·"æä¾›ï¼Œä¸æä¾›ä»»ä½•å½¢å¼çš„æ˜ç¤ºæˆ–æš—ç¤ºæ‹…ä¿ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº
å¯¹é€‚é”€æ€§ã€ç‰¹å®šç”¨é€”é€‚ç”¨æ€§å’Œéä¾µæƒæ€§çš„æ‹…ä¿ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œä½œè€…æˆ–ç‰ˆæƒ
æŒæœ‰äººå‡ä¸å¯¹å› è½¯ä»¶æˆ–è½¯ä»¶çš„ä½¿ç”¨æˆ–å…¶ä»–äº¤æ˜“è€Œäº§ç”Ÿçš„ä»»ä½•ç´¢èµ”ã€æŸå®³æˆ–å…¶ä»–
è´£ä»»è´Ÿè´£ï¼Œæ— è®ºæ˜¯å¥‘çº¦è¡Œä¸ºã€ä¾µæƒè¡Œä¸ºæˆ–å…¶ä»–è¡Œä¸ºã€‚
```

### ç¬¬ä¸‰æ–¹ç»„ä»¶

æœ¬é¡¹ç›®åŒ…å«æ¥è‡ªç¬¬ä¸‰æ–¹å¼€æºé¡¹ç›®çš„ç»„ä»¶ï¼š

- PyTorch (BSDè®¸å¯è¯)
- Flask (BSDè®¸å¯è¯)
- TorchVision (BSDè®¸å¯è¯)
- OpenCV (Apache 2.0è®¸å¯è¯)
- Bootstrap (MITè®¸å¯è¯)
- å…¶ä»–å„ç§åŒ…ï¼Œå¦‚requirements.txtä¸­æ‰€åˆ—
